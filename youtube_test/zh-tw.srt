1
00:00:00,000 --> 00:00:05,005
shasha77 被中國央視主播專訪

2
00:00:05,005 --> 00:00:07,841
面對面你的視頻記錄日常 傳遞善意

3
00:00:07,841 --> 00:00:09,309
吸引了很多年輕人

4
00:00:09,309 --> 00:00:10,777
你被稱為有為青年

5
00:00:10,777 --> 00:00:12,278
你覺得這個稱呼準確嗎

6
00:00:12,278 --> 00:00:13,980
能夠被大家這樣認可我

7
00:00:13,980 --> 00:00:15,815
歡迎來到央視面對面

8
00:00:15,815 --> 00:00:16,282
視頻記錄

9
00:00:33,233 --> 00:00:34,667
Hiho 大家好 我是志祺

10
00:00:34,667 --> 00:00:36,169
又回到我們今天不讀稿

11
00:00:36,169 --> 00:00:37,837
這系列我就不會看稿

12
00:00:37,837 --> 00:00:40,073
改用輕鬆聊聊的方式討論網紅圈 YouTube

13
00:00:40,073 --> 00:00:41,841
或是網路上面的一些熱門話題

14
00:00:41,841 --> 00:00:43,143
我們今天要討論的是

15
00:00:44,411 --> 00:00:47,113
因為大概這半年來大家應該看過非常多

16
00:00:47,113 --> 00:00:48,782
什麼貓貓狗狗的 AI 短影片

17
00:00:48,782 --> 00:00:49,983
什麼切東西

18
00:00:49,983 --> 00:00:51,351
揉麵什麼的

19
00:00:51,351 --> 00:00:52,318
那就是有種

20
00:00:53,853 --> 00:00:54,287
的感覺

21
00:00:54,287 --> 00:00:55,989
對 我覺得有看到一些討論

22
00:00:55,989 --> 00:00:57,891
他們是在說未來這些 AI 影片

23
00:00:57,891 --> 00:00:58,224
可能會

24
00:01:00,693 --> 00:01:01,995
所以我們就有點好奇

25
00:01:01,995 --> 00:01:04,931
目前這些 AI 影片到底能夠帶來多少的影響

26
00:01:04,931 --> 00:01:07,200
對 然後因為不只是創作者受影響

27
00:01:07,200 --> 00:01:08,401
我覺得其實一般人也會

28
00:01:08,401 --> 00:01:09,202
已經有一陣子了

29
00:01:09,202 --> 00:01:10,637
Sora 2 推出之後

30
00:01:10,637 --> 00:01:12,872
生成的影片真的我們覺得超級扯

31
00:01:12,872 --> 00:01:13,373
很真

32
00:01:13,373 --> 00:01:16,076
對 因為我們剛好在我們拍的這一天

33
00:01:16,076 --> 00:01:18,978
Gemini 它又開始推出他們的新的模型

34
00:01:18,978 --> 00:01:20,246
對 超級可怕

35
00:01:20,246 --> 00:01:21,514
會有越來越多人擔心說

36
00:01:21,514 --> 00:01:24,451
這種影片或是照片變得越來越真假難辨

37
00:01:24,451 --> 00:01:26,653
然後這種假資訊會變得越來越嚴重

38
00:01:26,653 --> 00:01:27,187
沒有錯

39
00:01:27,187 --> 00:01:28,688
所以今天這集我們就要來討論一下

40
00:01:28,688 --> 00:01:30,390
現在的 AI 影片到底有多少

41
00:01:30,390 --> 00:01:32,392
然後有哪些類型最常看到

42
00:01:32,392 --> 00:01:33,526
而這些技術有多強

43
00:01:33,526 --> 00:01:35,328
我們會直接試用 Sora 2 給大家看

44
00:01:35,328 --> 00:01:36,930
而且我們會結合專家說法

45
00:01:36,930 --> 00:01:39,232
還有加上我們自己的觀察來討論看看

46
00:01:39,232 --> 00:01:40,500
不過在開始今天討論之前

47
00:01:40,500 --> 00:01:42,469
先讓我們進一段工商服務時間

48
00:02:21,875 --> 00:02:23,343
好 我們就先來看看

49
00:02:23,343 --> 00:02:25,545
AI 影片到現在到底有多多好了

50
00:02:25,545 --> 00:02:26,446
就是我個人體感

51
00:02:26,446 --> 00:02:27,313
當然是覺得說

52
00:02:27,313 --> 00:02:29,048
今年滑到的比例變得高很多

53
00:02:29,048 --> 00:02:32,252
我覺得目前市面上面到底有多少的 AI 影片

54
00:02:32,252 --> 00:02:33,987
還沒有太確切的數據

55
00:02:33,987 --> 00:02:35,321
這確實蠻難統計的

56
00:02:35,321 --> 00:02:37,290
感覺數字會變化得非常非常地快

57
00:02:37,290 --> 00:02:40,126
但是我們整理了幾種很熱門的 AI 短片

58
00:02:40,126 --> 00:02:42,962
大致可以分成像是 ASMR 假訪談

59
00:02:42,962 --> 00:02:44,664
動物類還有假劇情等等

60
00:02:44,664 --> 00:02:46,065
這邊就給大家看一看

61
00:02:46,232 --> 00:02:49,035
首先我們就一起來看看這個 AI 的 ASMR

62
00:02:49,035 --> 00:02:50,670
對 它會直接做一個假的東西

63
00:02:50,670 --> 00:02:51,838
然後因為它看起來很漂亮

64
00:02:51,838 --> 00:02:52,672
而且很療癒

65
00:02:52,672 --> 00:02:53,273
對 對 對

66
00:02:53,273 --> 00:02:54,874
就真的很爽

67
00:02:54,874 --> 00:02:56,442
而且我覺得它有達成

68
00:02:56,442 --> 00:02:57,710
短影音它的一個重點

69
00:02:57,710 --> 00:02:57,977
就是

70
00:02:59,479 --> 00:03:00,480
因為它看起來太奇怪

71
00:03:00,480 --> 00:03:02,615
就有點像是 MrBeast 說的紫犀牛

72
00:03:02,615 --> 00:03:05,885
就你會忍不住多看個一次 兩次 三次

73
00:03:05,885 --> 00:03:08,488
然後甚至搭配聲音也覺得這有點超現實

74
00:03:08,488 --> 00:03:09,155
但它在

75
00:03:09,155 --> 00:03:11,991
現實跟超假之間的那個中間

76
00:03:11,991 --> 00:03:12,525
對 對 對

77
00:03:12,525 --> 00:03:14,961
再來我們來看看假訪談的這種類型

78
00:03:14,961 --> 00:03:16,663
這它們會生成兩個角色

79
00:03:16,663 --> 00:03:18,498
然後進行一段非常無厘頭的對話

80
00:03:18,498 --> 00:03:19,365
例如說第一個

81
00:03:19,365 --> 00:03:20,400
這個我們可以來看看

82
00:03:20,400 --> 00:03:22,135
AI 的記者採訪影片

83
00:03:22,135 --> 00:03:23,369
你怎麼知道自己是 AI 的

84
00:03:23,369 --> 00:03:25,438
我喝醉也會自動導航回家

85
00:03:25,438 --> 00:03:27,173
我每個月都要自己更新系統

86
00:03:27,173 --> 00:03:28,308
不然會當機

87
00:03:29,075 --> 00:03:30,677
你看後面的文字

88
00:03:30,677 --> 00:03:31,578
是對的

89
00:03:31,578 --> 00:03:32,011
沒有 沒有

90
00:03:32,011 --> 00:03:33,413
後面的文字會是假的

91
00:03:33,413 --> 00:03:35,181
但我覺得它至少是中文字

92
00:03:35,181 --> 00:03:36,849
對 對 看的時候感覺好像中文

93
00:03:36,849 --> 00:03:38,051
但其實是假的

94
00:03:38,051 --> 00:03:40,420
我覺得這個算是好分辨的

95
00:03:40,420 --> 00:03:42,355
可是如果我們把這樣的東西

96
00:03:42,355 --> 00:03:43,656
再套上更多的濾鏡

97
00:03:43,656 --> 00:03:44,057
對

98
00:03:44,057 --> 00:03:46,559
甚至是你把它做一點模糊 Blur

99
00:03:46,559 --> 00:03:46,993
你就會覺得

100
00:03:46,993 --> 00:03:48,194
好像

101
00:03:49,562 --> 00:03:50,763
而且我真的覺得字這個東西

102
00:03:50,763 --> 00:03:51,831
會是時間問題而已

103
00:03:51,831 --> 00:03:52,532
沒錯

104
00:03:52,532 --> 00:03:54,567
好 還有這個狗狗駕駛拒檢

105
00:03:54,567 --> 00:03:55,201
我們也來看一下

106
00:03:55,201 --> 00:03:56,402
你的駕照給我看一下

107
00:03:56,703 --> 00:03:58,538
我是狗 沒有駕照

108
00:03:58,538 --> 00:03:59,572
好爛

109
00:03:59,572 --> 00:04:00,673
不好意思

110
00:04:00,673 --> 00:04:01,140
等等

111
00:04:01,140 --> 00:04:02,108
停車

112
00:04:02,909 --> 00:04:03,743
這是夠瞎

113
00:04:04,377 --> 00:04:06,446
對 對 沒錯

114
00:04:06,446 --> 00:04:08,448
對 就整件事情就會讓你覺得

115
00:04:08,448 --> 00:04:08,982
哇

116
00:04:12,518 --> 00:04:14,320
我們來看看這個貓咪做菜

117
00:04:14,320 --> 00:04:16,656
好 這就揉揉麵團

118
00:04:17,123 --> 00:04:18,791
然後搭配療癒的感覺

119
00:04:19,125 --> 00:04:20,627
這個好像就是之前大家在講說

120
00:04:20,627 --> 00:04:22,729
老高在嘗試的那種東西

121
00:04:23,796 --> 00:04:24,998
好怕牠切到手

122
00:04:26,599 --> 00:04:28,001
你是貓派還是狗派(?)

123
00:04:28,635 --> 00:04:29,302
都還好。

124
00:04:31,137 --> 00:04:31,671
對

125
00:04:32,205 --> 00:04:32,672
不行

126
00:04:34,874 --> 00:04:37,877
最後一個我覺得是這種假劇情的

127
00:04:37,877 --> 00:04:40,013
它是用 AI 改真實的影片

128
00:04:40,013 --> 00:04:42,282
然後把人物替換成一些機器人這樣子

129
00:04:44,250 --> 00:04:45,518
很瞎欸...

130
00:04:46,786 --> 00:04:48,488
它是臺灣背景

131
00:04:50,423 --> 00:04:51,658
是我錯了 是我錯了

132
00:04:51,658 --> 00:04:53,693
真的是無所不用其極

133
00:04:54,961 --> 00:04:57,363
前面這幾個例子都是這幾個月爆出來

134
00:04:57,363 --> 00:04:58,298
超級多 超級紅

135
00:04:58,298 --> 00:05:01,000
我就常常在 IG 上面不停地滑到

136
00:05:01,000 --> 00:05:03,970
對 然後當然還會有一些那種超級多觀看

137
00:05:03,970 --> 00:05:05,238
我們剛剛看的都還好

138
00:05:05,238 --> 00:05:08,708
有幾種它可能是劇情沒有什麼邏輯

139
00:05:08,708 --> 00:05:09,809
看到的時候會讓人很問號

140
00:05:09,809 --> 00:05:12,378
但是莫名可能有個幾千萬觀看

141
00:05:12,378 --> 00:05:13,112
我們來看第一個

142
00:05:13,112 --> 00:05:14,614
這個有 9 千多萬觀看

143
00:05:17,317 --> 00:05:18,951

144
00:05:19,786 --> 00:05:20,853
這個 在幹嘛

145
00:05:20,853 --> 00:05:21,721
這個也還好

146
00:05:21,721 --> 00:05:22,689
但是你就不懂

147
00:05:22,689 --> 00:05:23,923
對 對 是不懂

148
00:05:23,923 --> 00:05:24,691
問題在於不懂

149
00:05:24,691 --> 00:05:26,192
你也不是覺得它很荒謬還是什麼

150
00:05:26,192 --> 00:05:26,793
而是不懂

151
00:05:27,193 --> 00:05:29,162
這個就是你想要的世界嗎(?)

152
00:05:29,162 --> 00:05:30,063
Google

153
00:05:30,530 --> 00:05:32,598
像這種就是我也大概看過不少

154
00:05:32,598 --> 00:05:34,200
這種就是雖然你很明顯知道

155
00:05:34,200 --> 00:05:35,735
它就是一個 AI 做的

156
00:05:35,735 --> 00:05:36,836
要嘛就是劇情很怪

157
00:05:36,836 --> 00:05:37,870
要嘛就是完全

158
00:05:37,870 --> 00:05:39,072
我也說不上來為什麼

159
00:05:39,072 --> 00:05:40,707
你就會往下看

160
00:05:40,707 --> 00:05:43,076
我覺得這些大概就是今年網路上面

161
00:05:43,076 --> 00:05:44,344
超多的這種短影片

162
00:05:44,344 --> 00:05:44,610
就反正

163
00:05:46,412 --> 00:05:47,847
我覺得我可以分享一個我個人觀察

164
00:05:47,847 --> 00:05:50,416
像我們前面講的那幾種大類

165
00:05:50,416 --> 00:05:52,318
我其實覺得它一個很聰明一點是

166
00:05:56,155 --> 00:05:57,790
對 就 ASMR 這些東西

167
00:05:57,790 --> 00:05:58,658
然後街訪

168
00:05:58,658 --> 00:05:59,592
然後短劇

169
00:05:59,592 --> 00:06:01,260
但它在轉成 AI 之後

170
00:06:01,260 --> 00:06:03,162
你很可以想像它就會非常好看

171
00:06:03,162 --> 00:06:03,629
沒錯

172
00:06:03,629 --> 00:06:04,464
而且很便宜

173
00:06:04,464 --> 00:06:06,499
我覺得 AI 的影片會變那麼多

174
00:06:06,499 --> 00:06:07,467
原因也很好想像

175
00:06:07,467 --> 00:06:08,735
就是現在技術越來越成熟了

176
00:06:08,735 --> 00:06:10,536
對 因為像 AI 模型提供商

177
00:06:12,071 --> 00:06:13,840
現在我們除了有 Veo 3

178
00:06:13,840 --> 00:06:15,742
我們有這個 Kling AI

179
00:06:15,742 --> 00:06:17,009
我們有 Sora 等等工具

180
00:06:17,009 --> 00:06:19,145
這個影片的生成能力是非常強的

181
00:06:19,145 --> 00:06:21,314
這邊我覺得我想要跟大家特別講一下 Sora

182
00:06:21,314 --> 00:06:24,083
因為它是 OpenAI 開發的生成式 AI 影片工具

183
00:06:24,083 --> 00:06:25,418
在這邊我們可以看一下

184
00:06:25,418 --> 00:06:27,687
就前陣子 Sora 有一個阿嬤餵熊的影片

185
00:06:27,687 --> 00:06:30,056
它在網路上面瘋傳

186
00:06:30,056 --> 00:06:32,158
你看它加上魚眼鏡頭

187
00:06:34,026 --> 00:06:34,494
對

188
00:06:34,494 --> 00:06:36,963
因為你就把原本人類覺得

189
00:06:36,963 --> 00:06:39,232
這正常視覺範圍我們看到的東西

190
00:06:39,232 --> 00:06:40,700
光影什麼東西都把它拿掉了

191
00:06:40,700 --> 00:06:41,467
它就看起來超真

192
00:06:41,467 --> 00:06:42,869
然後什麼監視器(鏡頭)之類的

193
00:06:42,869 --> 00:06:43,936
對 對 對 對 對

194
00:06:43,936 --> 00:06:45,171
我覺得像剛剛這些東西

195
00:06:49,509 --> 00:06:51,611
所以就有外媒在討論這件事情

196
00:06:51,611 --> 00:06:54,847
我看到很多那個他們拿山姆・奧特曼的影像

197
00:06:54,847 --> 00:06:57,683
然後讓他去偷那個顯示卡(?)

198
00:06:57,683 --> 00:06:58,751
到處去偷顯卡

199
00:06:59,619 --> 00:07:01,654
然後再被監視器拍到

200
00:07:02,488 --> 00:07:03,723
好 這邊我覺得

201
00:07:03,723 --> 00:07:05,124
可以現場試用一下

202
00:07:05,124 --> 00:07:06,392
來看看它到底多厲害

203
00:07:06,392 --> 00:07:09,061
現在這個地方就是它的這個介面

204
00:07:09,061 --> 00:07:10,930
我們這邊可以新增一個角色

205
00:07:10,930 --> 00:07:12,398
然後我們就可以建立一個角色

206
00:07:12,398 --> 00:07:14,534
讓它在影片裡面共同地出演

207
00:07:19,872 --> 00:07:20,973
這樣就上傳了

208
00:07:20,973 --> 00:07:21,641
超快

209
00:07:21,641 --> 00:07:22,708
超級快

210
00:07:22,708 --> 00:07:25,011
好 再來我們就可以來輸入指令

211
00:07:25,011 --> 00:07:26,979
創造一些奇怪的影片(?)

212
00:07:26,979 --> 00:07:28,414
來 這邊按加

213
00:07:28,414 --> 00:07:30,316
我們要做一些你絕對不會做的事

214
00:07:30,316 --> 00:07:32,051
好 我們來做

215
00:07:32,051 --> 00:07:34,287
張志祺吃海鮮吃得很開心

216
00:07:35,455 --> 00:07:38,658
吃海鮮跟生魚片大餐

217
00:07:38,658 --> 00:07:40,293
還有沙拉

218
00:07:40,293 --> 00:07:42,462
非常開心

219
00:07:44,864 --> 00:07:47,233
看看到底會拋出什麼樣的東西

220
00:07:47,934 --> 00:07:49,936
現在的prompt(提示詞)真的都超短

221
00:07:49,936 --> 00:07:51,304
對 以前我們還要想

222
00:07:51,304 --> 00:07:54,040
還要學會建一大堆的那個模板的

223
00:07:54,040 --> 00:07:55,208
這個風格叫什麼

224
00:07:55,208 --> 00:07:55,808
那個風格叫什麼

225
00:07:55,808 --> 00:07:56,509
才 3 年

226
00:07:56,509 --> 00:07:58,010
再 3 年到底會長怎麼樣

227
00:08:01,214 --> 00:08:02,148
第一個已經有了

228
00:08:02,148 --> 00:08:03,816
好噁 好像

229
00:08:05,351 --> 00:08:06,385
生魚片大餐

230
00:08:06,385 --> 00:08:07,720
這一盤超豐盛

231
00:08:07,720 --> 00:08:09,822
鮭魚入口即化 超好吃

232
00:08:09,822 --> 00:08:11,624
還有龍蝦 牡蠣 蝦子

233
00:08:11,624 --> 00:08:12,892
每一口都鮮甜

234
00:08:12,892 --> 00:08:14,360
清爽的沙拉

235
00:08:17,163 --> 00:08:19,832
你懂為什麼它要加魚眼鏡頭了吧

236
00:08:19,832 --> 00:08:20,900
就它加了之後

237
00:08:20,900 --> 00:08:23,102
那個變形會看起來就是很合理

238
00:08:23,102 --> 00:08:24,270
對 對 對 對 對

239
00:08:24,270 --> 00:08:25,972
但是 Sora 2 還是有些限制

240
00:08:25,972 --> 00:08:28,374
像是你不得生產這種侵犯智慧財產權

241
00:08:28,374 --> 00:08:29,542
或是假冒公眾人物

242
00:08:29,542 --> 00:08:32,178
然後未經同意使用其樣貌這種東西的內容

243
00:08:32,178 --> 00:08:33,646
使用者是可以決定

244
00:08:33,646 --> 00:08:35,248
自己的臉是否可以被二創的

245
00:08:35,248 --> 00:08:36,382
如果你不同意

246
00:08:36,382 --> 00:08:38,985
其他人就不可能夠拿你的臉去生成一些影片

247
00:08:38,985 --> 00:08:41,921
像我們的企劃他之前有嘗試生成

248
00:08:41,921 --> 00:08:44,624
志祺在中國央視報新聞的樣子

249
00:08:44,624 --> 00:08:46,759
結果被判定違反生成的規則

250
00:08:46,759 --> 00:08:48,594
我覺得這個東西可能就是因為

251
00:08:48,594 --> 00:08:50,963
那個時候我還沒有把自己的臉弄出來

252
00:08:50,963 --> 00:08:53,499
然後之後也沒有把這個肖像權開放給別人

253
00:08:53,499 --> 00:08:55,568
說不定等一下就可以來試試看

254
00:08:55,568 --> 00:08:59,372
我覺得這個只是 Sora 還有在自我限制

255
00:08:59,372 --> 00:08:59,972
對 對

256
00:08:59,972 --> 00:09:01,140
而且只要在競爭之下

257
00:09:01,140 --> 00:09:02,041
最後大家就會把它打開

258
00:09:02,041 --> 00:09:03,576
對 那個技術就是會達到

259
00:09:03,576 --> 00:09:04,510
我就覺得最可怕

260
00:09:04,510 --> 00:09:05,912
對我而言最有關係的是

261
00:09:05,912 --> 00:09:08,047
政治人物或是明星講話

262
00:09:08,047 --> 00:09:09,649
我已經有刷到一些了

263
00:09:09,649 --> 00:09:11,517
然後他就可能他某個爭議事件

264
00:09:11,517 --> 00:09:13,553
比如說什麼最近王子跟粿粿

265
00:09:13,553 --> 00:09:13,819
對

266
00:09:13,819 --> 00:09:16,255
然後他們就發布一個王子道歉

267
00:09:16,255 --> 00:09:17,223
他講了什麼

268
00:09:17,223 --> 00:09:18,291
太像真的了

269
00:09:18,291 --> 00:09:20,159
我們再來產另外一個好了

270
00:09:20,159 --> 00:09:25,398
shasha77 被中國央視主播專訪

271
00:09:34,674 --> 00:09:35,708
好

272
00:09:35,708 --> 00:09:36,242
看會長什麼

273
00:09:37,677 --> 00:09:38,945
下一個也要好了

274
00:09:38,945 --> 00:09:39,645
居然讓你產

275
00:09:39,645 --> 00:09:40,780
我以為它會擋你

276
00:09:40,780 --> 00:09:41,547
不會 不會

277
00:09:41,547 --> 00:09:42,415
我這個是

278
00:09:47,019 --> 00:09:48,588
我覺得這種真的是很可怕

279
00:09:48,588 --> 00:09:50,323
我覺得現在等於說你錄音

280
00:09:50,323 --> 00:09:51,724
或是那種什麼錄影證據

281
00:09:51,724 --> 00:09:52,658
比如說監視器拍到

282
00:09:52,658 --> 00:09:53,626
你都沒辦法相信了

283
00:09:53,626 --> 00:09:54,360
已經來了

284
00:09:54,360 --> 00:09:55,094
要不要看

285
00:09:55,094 --> 00:09:55,461
好。

286
00:09:55,461 --> 00:09:56,596
很像

287
00:09:56,596 --> 00:09:59,265
面對面你的視頻記錄日常傳遞善意

288
00:09:59,265 --> 00:10:00,766
吸引了很多年輕人

289
00:10:00,766 --> 00:10:02,234
你被稱為有為青年

290
00:10:02,234 --> 00:10:03,703
你覺得這個稱呼準確嗎

291
00:10:03,703 --> 00:10:05,404
能夠被大家這樣認可我

292
00:10:05,404 --> 00:10:07,139
歡迎來到央視面對面

293
00:10:07,139 --> 00:10:08,040
你的視頻紀錄

294
00:10:10,343 --> 00:10:11,811
那個笑容好像

295
00:10:13,179 --> 00:10:14,113
好可怕

296
00:10:15,081 --> 00:10:16,849
我們這個可不可以發一支 Short(?)

297
00:10:21,387 --> 00:10:22,855
天啊 好可怕

298
00:10:24,957 --> 00:10:26,325
能夠被大家這樣認可

299
00:10:26,325 --> 00:10:27,526
真的是非常地開心

300
00:10:28,361 --> 00:10:29,829
好可怕

301
00:10:30,262 --> 00:10:32,198
講了那麼多這種好像有點好笑

302
00:10:32,198 --> 00:10:33,165
或是娛樂的內容

303
00:10:33,165 --> 00:10:35,534
就是我其實還是覺得應該回去講一下

304
00:10:35,534 --> 00:10:37,570
這種 AI 影片它會有些爭議的地方

305
00:10:37,570 --> 00:10:39,372
我覺得 AI 影片它蠻大的隱憂

306
00:10:39,372 --> 00:10:41,207
當然還是假訊息跟錯誤資訊

307
00:10:41,207 --> 00:10:42,842
快速擴散這些問題

308
00:10:42,842 --> 00:10:45,044
因為目前短影音跟長影片

309
00:10:45,044 --> 00:10:46,545
我們都有找到一些不同的案例

310
00:10:46,545 --> 00:10:47,880
所以這邊可以讓我們來看看

311
00:10:47,880 --> 00:10:49,115
這個短影音的案例

312
00:10:49,115 --> 00:10:51,117
這邊就有一個 10 月美國堪薩斯

313
00:10:51,117 --> 00:10:53,285
他們下起了一個巨大的冰雹

314
00:10:53,285 --> 00:10:54,220
你看一下

315
00:10:57,523 --> 00:10:59,659
它確實有它的真實感

316
00:10:59,659 --> 00:11:01,060
但真的很瞎

317
00:11:01,060 --> 00:11:02,361
真的有人信嗎

318
00:11:02,361 --> 00:11:04,063
好 可能還是會有人

319
00:11:04,063 --> 00:11:06,032
對 我覺得先不撇除掉

320
00:11:06,032 --> 00:11:07,667
中間的這個大大的東西

321
00:11:07,667 --> 00:11:10,369
它旁邊看起來的真實感很高

322
00:11:10,369 --> 00:11:10,670
對

323
00:11:10,670 --> 00:11:11,570
所以這個時候在

324
00:11:11,570 --> 00:11:14,173
你今天是放空地在看短音的時候

325
00:11:14,173 --> 00:11:16,242
你確實會懷疑這怎麼了

326
00:11:16,242 --> 00:11:18,344
然後另外像這種染色的水果

327
00:11:18,344 --> 00:11:19,645
這個我看不出破綻

328
00:11:19,645 --> 00:11:20,212
坦白說

329
00:11:21,714 --> 00:11:22,782
這個我真的看不出來

330
00:11:23,149 --> 00:11:23,482
慘了

331
00:11:26,886 --> 00:11:29,088
或是這個達美航空

332
00:11:33,859 --> 00:11:35,127
這個看不出來

333
00:11:35,127 --> 00:11:37,063
我覺得這個你沒有仔細看真的看不出來

334
00:11:37,063 --> 00:11:38,397
對 誰在短影音的時候

335
00:11:38,397 --> 00:11:38,998
你會很仔細地看

336
00:11:38,998 --> 00:11:39,331
對

337
00:11:39,331 --> 00:11:40,833
所以我覺得我們很簡單地看

338
00:11:40,833 --> 00:11:44,437
就可以看到很多很多可能的問題

339
00:11:44,437 --> 00:11:44,837
對

340
00:11:44,837 --> 00:11:47,373
像剛剛這些東西其實是台灣事實查核中心

341
00:11:47,373 --> 00:11:50,242
他們已經證實說這個是 AI 生成的假影像

342
00:11:50,242 --> 00:11:51,811
我覺得有些相對還好查證

343
00:11:51,811 --> 00:11:53,312
因為你可能可以去查一些

344
00:11:53,312 --> 00:11:55,314
新聞媒體有沒有報導你就知道了

345
00:11:55,314 --> 00:11:56,515
但反而是那種

346
00:11:59,318 --> 00:12:02,188
這邊我想要給大家看看兩個長影片的頻道

347
00:12:02,188 --> 00:12:03,022
就在查資料的時候

348
00:12:03,022 --> 00:12:05,391
我看到 Threads 上面有不同的網友發文說

349
00:12:05,391 --> 00:12:06,625
發現家裡面的長輩

350
00:12:06,625 --> 00:12:08,294
在看一些自稱是醫師的 YouTube 頻道

351
00:12:08,294 --> 00:12:10,463
結果點進去看內容覺得怪怪的

352
00:12:10,463 --> 00:12:11,697
例如像這一個

353
00:12:11,697 --> 00:12:14,500
像是這個就是陳志明醫師的頻道

354
00:12:14,500 --> 00:12:16,635
他目前有超過 100 支跟糖尿病有關影片

355
00:12:16,635 --> 00:12:17,570
我們可以來看一下

356
00:12:17,570 --> 00:12:19,438
就是你看它的那個橫幅

357
00:12:19,438 --> 00:12:20,906
它就有一個明顯的 AI 感

358
00:12:20,906 --> 00:12:21,373
對

359
00:12:21,707 --> 00:12:23,175
但我覺得你如果你看縮圖

360
00:12:23,175 --> 00:12:24,210
我會看不出來

361
00:12:24,210 --> 00:12:24,443
對

362
00:12:24,443 --> 00:12:26,212
其實我是從它背景那邊推得出來

363
00:12:26,212 --> 00:12:27,213
這種油光油光的

364
00:12:27,213 --> 00:12:28,581
但縮圖就是看不出來

365
00:12:31,383 --> 00:12:32,017
是吧

366
00:12:32,017 --> 00:12:33,786
所以他就這樣子狂洗(影片)

367
00:12:33,786 --> 00:12:34,854
然後洗一大堆

368
00:12:34,854 --> 00:12:36,288
其實事實查核單位就是 MyGoPen

369
00:12:36,288 --> 00:12:37,590
他們已經有證實說

370
00:12:41,594 --> 00:12:43,662
像這個內容就已經被證實說

371
00:12:43,662 --> 00:12:45,397
它的內容本身是有錯的

372
00:12:45,397 --> 00:12:46,465
然後還有

373
00:12:46,465 --> 00:12:49,268
大部分提到的研究都沒有明確的出處

374
00:12:49,268 --> 00:12:50,136
我覺得可怕的是

375
00:12:50,136 --> 00:12:51,871
就是他在講的是醫療

376
00:12:51,871 --> 00:12:52,972
就是你真的很容易

377
00:12:55,207 --> 00:12:59,078
對 像是之前我們訪那個牙醫師陳鉉

378
00:12:59,078 --> 00:13:01,080
然後他就有說他覺得一個很大的困難就是

379
00:13:04,183 --> 00:13:05,050
然後來質疑你

380
00:13:05,050 --> 00:13:05,985
對 對 他來質疑

381
00:13:05,985 --> 00:13:06,685
然後就想說

382
00:13:08,254 --> 00:13:09,622
然後你還拿來質疑我

383
00:13:09,622 --> 00:13:10,723
到底該怎麼辦

384
00:13:10,723 --> 00:13:13,292
另外你看這個是一個智慧之泉的頻道

385
00:13:13,292 --> 00:13:14,260
它一樣的問題

386
00:13:14,260 --> 00:13:15,027
你看它超多

387
00:13:15,027 --> 00:13:16,829
它 22.6 萬訂閱

388
00:13:16,829 --> 00:13:17,496
超扯

389
00:13:17,496 --> 00:13:18,430
80 幾部影片而已

390
00:13:18,430 --> 00:13:18,764
對

391
00:13:18,764 --> 00:13:20,232
因為醫療相關的事情

392
00:13:20,232 --> 00:13:22,935
非常容易做出一些看起來很緊急

393
00:13:22,935 --> 00:13:24,336
然後你一定需要注意

394
00:13:24,336 --> 00:13:25,871
而且有衝突性的內容

395
00:13:25,871 --> 00:13:27,406
一般人很難有那個專業知識

396
00:13:27,406 --> 00:13:28,808
馬上看出說這個是假的

397
00:13:28,808 --> 00:13:29,942
對 對 對 對 對 對

398
00:13:29,942 --> 00:13:30,543
然後像這個

399
00:13:30,543 --> 00:13:33,045
甚至他還在講詐騙相關的事情

400
00:13:33,045 --> 00:13:34,180
這個很荒謬

401
00:13:34,180 --> 00:13:36,315
他自稱他是什麼 20 年資安專家

402
00:13:36,315 --> 00:13:36,782
對 對 對

403
00:13:36,782 --> 00:13:39,018
就這個頻道裡面有很多醫生

404
00:13:39,018 --> 00:13:40,986
什麼來自於神經內科 骨科

405
00:13:40,986 --> 00:13:42,421
都當醫生幾十年之類

406
00:13:44,690 --> 00:13:45,825
而且我覺得那個有趣的是

407
00:13:45,825 --> 00:13:47,226
它觀看次數還蠻高的

408
00:13:47,226 --> 00:13:49,862
就是在看熱門影片都有 80~90 萬

409
00:13:49,862 --> 00:13:51,797
我覺得這個東西的危險是在於說

410
00:13:53,666 --> 00:13:56,168
這裡面的這些自稱是醫生的人物

411
00:13:56,168 --> 00:13:57,303
其實都是假的

412
00:13:57,303 --> 00:13:58,771
他們可能會想說看完影片

413
00:13:58,771 --> 00:13:59,672
醫生的話要聽

414
00:13:59,672 --> 00:14:01,640
所以就隨手把這些內容

415
00:14:01,640 --> 00:14:03,075
發到一個 Line 群組裡面

416
00:14:03,075 --> 00:14:04,977
然後你就會看到這種假醫生說的話

417
00:14:04,977 --> 00:14:06,345
會不斷不斷地傳播

418
00:14:06,345 --> 00:14:07,479
我覺得這樣真的會麻煩

419
00:14:07,479 --> 00:14:08,581
這個頻道裡面

420
00:14:08,581 --> 00:14:10,149
它其實是有在資訊欄裡面

421
00:14:10,149 --> 00:14:12,585
有露出自己是變造或合成的內容

422
00:14:12,585 --> 00:14:16,422
但這也只能夠顯示影片包含 AI 創作內容

423
00:14:16,422 --> 00:14:19,024
針對影片杜撰這個人物或是資訊

424
00:14:19,024 --> 00:14:20,326
你好像沒有辦法管

425
00:14:20,326 --> 00:14:22,361
志祺 你有沒有覺得做為一個創作者

426
00:14:22,361 --> 00:14:24,930
這些 AI 影片對產業可能會有什麼問題

427
00:14:24,930 --> 00:14:26,131
我覺得最直接的影響

428
00:14:26,131 --> 00:14:27,166
應該還是這個

429
00:14:29,235 --> 00:14:32,638
像我們之前就發現 MrBeast 他也有發文說

430
00:14:32,638 --> 00:14:34,039
他擔心 AI 影片的發展

431
00:14:34,039 --> 00:14:36,141
會對於影片創作者帶來一些衝擊

432
00:14:36,141 --> 00:14:38,611
就是連全世界最大的 YouTuber 都擔心

433
00:14:38,611 --> 00:14:41,213
對 我自己覺得這可以從幾個方面來看

434
00:14:41,213 --> 00:14:42,414
第一個是當然

435
00:14:43,782 --> 00:14:46,385
現在很多平台的這個廣告分潤機制

436
00:14:46,385 --> 00:14:49,321
它當然多多少少是根據影片的觀看數

437
00:14:49,321 --> 00:14:50,122
還有觀看時長

438
00:14:50,122 --> 00:14:51,857
在 AI 影片越來越多的情況之下

439
00:14:51,857 --> 00:14:52,424
就代表著

440
00:14:55,427 --> 00:14:56,161
舉例來說

441
00:14:56,161 --> 00:14:57,897
以前可能是 1 千部影片好了

442
00:14:57,897 --> 00:15:00,099
在競爭同樣的一個廣告預算

443
00:15:00,099 --> 00:15:02,101
但現在可能同時變成 1 萬部

444
00:15:02,101 --> 00:15:03,235
甚至更多在競爭

445
00:15:03,235 --> 00:15:05,571
每個人的分潤自然當然就變少了

446
00:15:05,571 --> 00:15:06,672
然後第二個是

447
00:15:07,806 --> 00:15:09,341
這個東西我覺得就比較好想像

448
00:15:09,341 --> 00:15:10,910
像我們這種真人拍的影片

449
00:15:10,910 --> 00:15:12,511
因為成本 人力等等關係

450
00:15:14,914 --> 00:15:15,781
所以之後我們想要

451
00:15:15,781 --> 00:15:17,816
在成堆的 AI 影片裡面曝光

452
00:15:17,816 --> 00:15:18,617
可能就越來越難

453
00:15:18,617 --> 00:15:19,485
剛剛講到的

454
00:15:19,485 --> 00:15:23,322
AI 影片它更容易做出看起來很衝突

455
00:15:23,322 --> 00:15:24,990
很想要點擊的東西

456
00:15:24,990 --> 00:15:26,125
而且他們成本相對低＊口誤

457
00:15:26,125 --> 00:15:27,226
他們可能可以做 100 支

458
00:15:27,226 --> 00:15:28,060
然後賭 1 支中

459
00:15:28,060 --> 00:15:30,296
這個時候一般人的價值

460
00:15:30,296 --> 00:15:31,931
或者是大家付出的努力

461
00:15:31,931 --> 00:15:33,632
多少會受到一點衝擊

462
00:15:33,632 --> 00:15:35,401
然後當然心理上面也會有點壓力

463
00:15:35,401 --> 00:15:38,237
當 AI 也是一個競爭對手的時候

464
00:15:38,237 --> 00:15:40,906
創作者可能多多少少會產生這種

465
00:15:40,906 --> 00:15:43,208
自己花了大量時間精力拍的影片

466
00:15:43,208 --> 00:15:45,878
竟然比不過一個 AI 10 分鐘生成影片的

467
00:15:45,878 --> 00:15:46,946
這種心理壓力

468
00:15:48,747 --> 00:15:51,216
對 這個該怎麼辦

469
00:15:51,750 --> 00:15:52,384
那怎麼辦

470
00:15:52,384 --> 00:15:53,319
你就要放棄嗎

471
00:15:53,819 --> 00:15:55,354
我每次聊到這個後面就是

472
00:15:55,354 --> 00:15:56,288
結局都走向

473
00:15:56,288 --> 00:15:56,922
我們要關門了(?)

474
00:15:56,922 --> 00:15:58,123
對 對 對 對 對

475
00:16:00,459 --> 00:16:03,896
好 我覺得這邊當然我並不想那麼快地放棄

476
00:16:03,896 --> 00:16:06,165
可是如果我們不想要放棄的話

477
00:16:06,165 --> 00:16:08,133
我們就要在這個時間點好好地思考一下

478
00:16:09,768 --> 00:16:11,937
像是如果我們單純比影片的生產速度

479
00:16:11,937 --> 00:16:13,138
人類是比不上的

480
00:16:13,138 --> 00:16:14,540
但是人類多多少少

481
00:16:14,540 --> 00:16:16,308
可能有一些 AI 不可取代之處

482
00:16:16,308 --> 00:16:17,910
像是你個人特色

483
00:16:17,910 --> 00:16:18,911
你個人的經歷

484
00:16:18,911 --> 00:16:21,513
你跟觀眾的這個關係還有連結

485
00:16:21,513 --> 00:16:24,183
這些東西它其實都是需要實際的體驗

486
00:16:24,183 --> 00:16:25,050
跟經營的東西

487
00:16:25,050 --> 00:16:25,517
我覺得 

488
00:16:27,720 --> 00:16:28,454
舉例來說

489
00:16:28,454 --> 00:16:30,756
AI 可以生成某個人去某個國家

490
00:16:30,756 --> 00:16:32,057
地方旅遊的畫面

491
00:16:32,057 --> 00:16:35,327
但實際上那個人在當地發生什麼樣的事情

492
00:16:35,327 --> 00:16:36,528
如何跟人互動

493
00:16:36,528 --> 00:16:38,030
各種的體驗心得

494
00:16:38,030 --> 00:16:40,032
甚至是要追溯到

495
00:16:40,032 --> 00:16:42,868
這個地方好像是我小時候的某某東西

496
00:16:42,868 --> 00:16:44,236
像是我出去吃飯常說

497
00:16:44,236 --> 00:16:45,637
這個很像是我阿公煮的

498
00:16:45,637 --> 00:16:46,672
這個很像是什麼

499
00:16:46,672 --> 00:16:47,806
在這個狀態之下

500
00:16:47,806 --> 00:16:50,309
它或許沒有辦法描述得那麼地鉅細靡遺

501
00:16:50,309 --> 00:16:52,511
當然描述得鉅細靡遺好不好

502
00:16:52,511 --> 00:16:53,078
不一定

503
00:16:53,078 --> 00:16:54,713
可是至少這個連結

504
00:16:54,713 --> 00:16:57,116
我覺得是目前 AI 沒有辦法給出的資訊

505
00:16:57,116 --> 00:16:58,050
關於這個部分

506
00:16:58,050 --> 00:16:59,785
我們就有點好奇專家的看法

507
00:16:59,785 --> 00:17:01,153
所以在這邊我們找到了

508
00:17:01,153 --> 00:17:03,255
一個英國教授他的研究

509
00:17:03,255 --> 00:17:04,456
我們可以一起來看一看

510
00:17:04,456 --> 00:17:07,426
他就在講說 MrBeast 不太可能被取代

511
00:17:07,426 --> 00:17:08,961
因為 MrBeast 大部分的影片

512
00:17:08,961 --> 00:17:10,596
是想要讓人為了錢

513
00:17:10,596 --> 00:17:12,531
做一些不舒服或危險的事情

514
00:17:12,531 --> 00:17:15,234
觀眾他們其實就是想要看

515
00:17:15,234 --> 00:17:18,170
這個 MrBeast 跟挑戰者之間真實的互動反應

516
00:17:18,170 --> 00:17:19,171
而這個比較細微

517
00:17:19,171 --> 00:17:20,706
所以 AI 很難真的做出來

518
00:17:23,642 --> 00:17:25,611
我想要看真的人血流成河(?)

519
00:17:25,611 --> 00:17:27,246
我才不要看 AI 血流成河(??)

520
00:17:27,713 --> 00:17:30,215
對 這就是真實體驗的部分

521
00:17:30,215 --> 00:17:31,884
我們如果從另外一個角度來看

522
00:17:31,884 --> 00:17:34,153
就是廠商在選擇合作對象的時候

523
00:17:34,153 --> 00:17:36,155
他們要的其實當然也不只是流量

524
00:17:36,155 --> 00:17:37,890
還有另外一個很重要的是可信度

525
00:17:37,890 --> 00:17:38,223
對 對

526
00:17:38,223 --> 00:17:40,692
像前面提到的那些 AI 醫生的頻道

527
00:17:40,692 --> 00:17:41,927
就算流量再高

528
00:17:41,927 --> 00:17:44,563
我也蠻能夠想像說會有正規的廠商

529
00:17:44,563 --> 00:17:46,465
敢冒這個風險去找他們業配

530
00:17:46,465 --> 00:17:47,866
因為多多少少就是

531
00:17:47,866 --> 00:17:49,401
你可信嗎？

532
00:17:49,401 --> 00:17:51,470
然後之所以我覺得至少在短期方面

533
00:17:51,470 --> 00:17:53,572
像從信任 經歷這些方面來

534
00:17:53,572 --> 00:17:56,341
其實人還是有一點點不可取代的價值

535
00:17:56,341 --> 00:17:58,644
對一般人來說他們可以怎麼做呢

536
00:17:58,644 --> 00:18:00,746
我覺得是要知道說

537
00:18:00,746 --> 00:18:03,916
哪些資訊是比較容易有危險的

538
00:18:03,916 --> 00:18:06,118
像涉及到專業領域的知識跟內容

539
00:18:06,118 --> 00:18:09,521
還是找確定是真人的專業人士諮詢比較好

540
00:18:09,521 --> 00:18:11,223
你看到任何的新聞或是資訊

541
00:18:11,223 --> 00:18:12,224
不要一開始就相信

542
00:18:13,058 --> 00:18:15,327
我覺得這某種程度它其實是好事

543
00:18:15,327 --> 00:18:17,830
它是在用這種海量的資訊

544
00:18:17,830 --> 00:18:21,800
去鍛鍊一般人原本過去很難去做的媒體識讀

545
00:18:21,800 --> 00:18:23,268
因為你現在不得不了

546
00:18:23,268 --> 00:18:24,903
以前你可能偶爾被騙一下

547
00:18:24,903 --> 00:18:25,771
你就覺得算了

548
00:18:25,771 --> 00:18:27,339
反正影響很遠

549
00:18:27,339 --> 00:18:29,541
但現在可能是你每天三不五時

550
00:18:29,541 --> 00:18:30,843
你所有的資訊都是假的

551
00:18:30,843 --> 00:18:33,245
這個時候你就需要很認真地去審核＊口誤

552
00:18:33,245 --> 00:18:36,014
當然我這邊我想要強調另外一件事情

553
00:18:36,014 --> 00:18:37,749
就是說使用 AI 製作影片

554
00:18:37,749 --> 00:18:40,119
或是成為一個 AI 創作者並不是不好的

555
00:18:40,119 --> 00:18:41,620
我們前面其實只是想要

556
00:18:41,620 --> 00:18:43,322
把這些可能的問題點點出來

557
00:18:43,322 --> 00:18:45,124
像前面提到這種動物 AI 影片

558
00:18:45,124 --> 00:18:46,558
我覺得基本上蠻有創意的

559
00:18:46,558 --> 00:18:47,626
就是娛樂度很高

560
00:18:47,626 --> 00:18:48,327
對 對 對

561
00:18:48,327 --> 00:18:49,928
我自己平常也會覺得

562
00:18:49,928 --> 00:18:50,996
這個真的做得很好

563
00:18:50,996 --> 00:18:51,864
這要怎麼做

564
00:18:51,864 --> 00:18:53,198
然後有些東西我會想說

565
00:18:53,198 --> 00:18:56,068
我該怎麼樣把它納到我們工作流程裡面

566
00:18:56,068 --> 00:18:57,536
讓我們自己可以去使用

567
00:18:57,536 --> 00:18:57,903
因為畢竟

568
00:19:00,038 --> 00:19:01,573
把想像化為一個真實影片

569
00:19:01,573 --> 00:19:02,941
其實非常厲害

570
00:19:02,941 --> 00:19:06,178
甚至最近我們看到那個 Gemini 3

571
00:19:06,178 --> 00:19:07,946
Nano Banana Pro 真的超強

572
00:19:07,946 --> 00:19:08,647
對 超強

573
00:19:08,647 --> 00:19:10,415
它就是講兩句話

574
00:19:10,415 --> 00:19:11,183
它就做出來了

575
00:19:11,183 --> 00:19:11,517
然後我就想

576
00:19:11,517 --> 00:19:13,719
哇 這過去做那種社群素材的人

577
00:19:13,719 --> 00:19:14,887
他到底該怎麼辦

578
00:19:15,220 --> 00:19:16,488
真的是太兇殘

579
00:19:16,488 --> 00:19:17,022
真的

580
00:19:17,022 --> 00:19:19,324
對 可是如果換一個角度來講

581
00:19:19,324 --> 00:19:21,226
這就是 AI 真的幫助人類

582
00:19:21,226 --> 00:19:22,761
把生產力拉得非常非常高

583
00:19:22,761 --> 00:19:24,062
這是一個很強大的助力

584
00:19:24,062 --> 00:19:25,497
最後我們要怎麼樣面對

585
00:19:25,497 --> 00:19:27,933
我覺得我們還是要持續地觀察下去

586
00:19:27,933 --> 00:19:29,401
好 今天就先到這邊

587
00:19:29,401 --> 00:19:30,369
我想問問大家

588
00:19:30,369 --> 00:19:32,838
就是你平常最常看到哪種 AI 影片呢

